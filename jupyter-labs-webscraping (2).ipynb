{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Space X  Falcon 9 First Stage Landing Prediction**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping Falcon 9 and Falcon Heavy Launches Records from Wikipedia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **40** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will be performing web scraping to collect Falcon 9 historical launch records from a Wikipedia page titled `List of Falcon 9 and Falcon Heavy launches`\n",
    "\n",
    "https://en.wikipedia.org/wiki/List_of_Falcon_9_and_Falcon_Heavy_launches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_1_L2/images/Falcon9_rocket_family.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falcon 9 first stage will land successfully\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/Images/landing_1.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several examples of an unsuccessful landing are shown here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/Images/crash.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specifically, the launch records are stored in a HTML table shown below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_1_L2/images/falcon9-launches-wiki.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Objectives\n",
    "Web scrap Falcon 9 launch records with `BeautifulSoup`: \n",
    "- Extract a Falcon 9 launch records HTML table from Wikipedia\n",
    "- Parse the table and convert it into a Pandas data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import required packages for this lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install beautifulsoup4\n",
    "!pip3 install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we will provide some helper functions for you to process web scraped HTML table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def date_time(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the data and time from the HTML  table cell\n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    return [data_time.strip() for data_time in list(table_cells.strings)][0:2]\n",
    "\n",
    "def booster_version(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the booster version from the HTML  table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    out=''.join([booster_version for i,booster_version in enumerate( table_cells.strings) if i%2==0][0:-1])\n",
    "    return out\n",
    "\n",
    "def landing_status(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the landing status from the HTML table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    out=[i for i in table_cells.strings][0]\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_mass(table_cells):\n",
    "    mass=unicodedata.normalize(\"NFKD\", table_cells.text).strip()\n",
    "    if mass:\n",
    "        mass.find(\"kg\")\n",
    "        new_mass=mass[0:mass.find(\"kg\")+2]\n",
    "    else:\n",
    "        new_mass=0\n",
    "    return new_mass\n",
    "\n",
    "\n",
    "def extract_column_from_header(row):\n",
    "    \"\"\"\n",
    "    This function returns the landing status from the HTML table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    if (row.br):\n",
    "        row.br.extract()\n",
    "    if row.a:\n",
    "        row.a.extract()\n",
    "    if row.sup:\n",
    "        row.sup.extract()\n",
    "        \n",
    "    colunm_name = ' '.join(row.contents)\n",
    "    \n",
    "    # Filter the digit and empty names\n",
    "    if not(colunm_name.strip().isdigit()):\n",
    "        colunm_name = colunm_name.strip()\n",
    "        return colunm_name    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the lab tasks consistent, you will be asked to scrape the data from a snapshot of the  `List of Falcon 9 and Falcon Heavy launches` Wikipage updated on\n",
    "`9th June 2021`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "static_url = \"https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, request the HTML page from the above URL and get a `response` object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1: Request the Falcon9 Launch Wiki page from its URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's perform an HTTP GET method to request the Falcon9 Launch HTML page, as an HTTP response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request was successful!\n"
     ]
    }
   ],
   "source": [
    "# use requests.get() method with the provided static_url\n",
    "# assign the response to a object\n",
    "import requests\n",
    "\n",
    "# Define the URL of the Falcon9 Launch Wiki page\n",
    "url = 'https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922'\n",
    "\n",
    "# Perform an HTTP GET request to fetch the page\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check the status of the response\n",
    "if response.status_code == 200:\n",
    "    print(\"Request was successful!\")\n",
    "    html_content = response.text  # Store the HTML content\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `BeautifulSoup` object from the HTML `response`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Falcon 9 and Falcon Heavy launches - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "# Use BeautifulSoup() to create a BeautifulSoup object from a response text content\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Assuming 'response' contains the HTML response from the GET request\n",
    "html_content = response.text\n",
    "\n",
    "# Create a BeautifulSoup object and specify the parser\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Print the title of the page to verify\n",
    "print(soup.title.string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the page title to verify if the `BeautifulSoup` object was created properly \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request was successful!\n",
      "Page Title: List of Falcon 9 and Falcon Heavy launches - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "# Use soup.title attribute\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Define the URL of the Falcon9 Launch Wiki page\n",
    "url = 'https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922'\n",
    "\n",
    "# Perform an HTTP GET request to fetch the page\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Request was successful!\")\n",
    "    html_content = response.text  # Store the HTML content\n",
    "\n",
    "    # Create a BeautifulSoup object and specify the parser\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Print the title of the page to verify\n",
    "    print(\"Page Title:\", soup.title.string)\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2: Extract all column/variable names from the HTML table header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to collect all relevant column names from the HTML table header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find all tables on the wiki page first. If you need to refresh your memory about `BeautifulSoup`, please check the external reference link towards the end of this lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request was successful!\n",
      "\n",
      "Table 1 headers:\n",
      "\n",
      "Table 2 headers:\n",
      "\n",
      "Table 3 headers:\n",
      "Flight No.\n",
      "Date andtime (UTC)\n",
      "Version,Booster [b]\n",
      "Launch site\n",
      "Payload[c]\n",
      "Payload mass\n",
      "Orbit\n",
      "Customer\n",
      "Launchoutcome\n",
      "Boosterlanding\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "\n",
      "Table 4 headers:\n",
      "Flight No.\n",
      "Date andtime (UTC)\n",
      "Version,Booster[b]\n",
      "Launch site\n",
      "Payload[c]\n",
      "Payload mass\n",
      "Orbit\n",
      "Customer\n",
      "Launchoutcome\n",
      "Boosterlanding\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "\n",
      "Table 5 headers:\n",
      "Flight No.\n",
      "Date andtime (UTC)\n",
      "Version,Booster[b]\n",
      "Launch site\n",
      "Payload[c]\n",
      "Payload mass\n",
      "Orbit\n",
      "Customer\n",
      "Launchoutcome\n",
      "Boosterlanding\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "\n",
      "Table 6 headers:\n",
      "Flight No.\n",
      "Date andtime (UTC)\n",
      "Version,Booster[b]\n",
      "Launch site\n",
      "Payload[c]\n",
      "Payload mass\n",
      "Orbit\n",
      "Customer\n",
      "Launchoutcome\n",
      "Boosterlanding\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "N/A [e]\n",
      "\n",
      "Table 7 headers:\n",
      "Flight No.\n",
      "Date andtime (UTC)\n",
      "Version,Booster[b]\n",
      "Launch site\n",
      "Payload[c]\n",
      "Payload mass\n",
      "Orbit\n",
      "Customer\n",
      "Launchoutcome\n",
      "Boosterlanding\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "\n",
      "Table 8 headers:\n",
      "Flight No.\n",
      "Date andtime (UTC)\n",
      "Version,Booster[b]\n",
      "Launch site\n",
      "Payload[c]\n",
      "Payload mass\n",
      "Orbit\n",
      "Customer\n",
      "Launchoutcome\n",
      "Boosterlanding\n",
      "47\n",
      "48\n",
      "FH 1\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "\n",
      "Table 9 headers:\n",
      "Flight No.\n",
      "Date andtime (UTC)\n",
      "Version,Booster[b]\n",
      "Launchsite\n",
      "Payload[c]\n",
      "Payload mass\n",
      "Orbit\n",
      "Customer\n",
      "Launchoutcome\n",
      "Boosterlanding\n",
      "67\n",
      "68\n",
      "69\n",
      "FH 2\n",
      "70\n",
      "71\n",
      "72\n",
      "FH 3\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "\n",
      "Table 10 headers:\n",
      "Flight No.\n",
      "Date andtime (UTC)\n",
      "Version,Booster[b]\n",
      "Launchsite\n",
      "Payload[c]\n",
      "Payload mass\n",
      "Orbit\n",
      "Customer\n",
      "Launchoutcome\n",
      "Boosterlanding\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "\n",
      "Table 11 headers:\n",
      "Flight\n",
      "No.\n",
      "Date andtime (UTC)\n",
      "Version,Booster[b]\n",
      "Launchsite\n",
      "Payload[c]\n",
      "Payload mass\n",
      "Orbit\n",
      "Customer\n",
      "Launchoutcome\n",
      "Boosterlanding\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "\n",
      "Table 12 headers:\n",
      "Date and time (UTC)\n",
      "Version,Booster[b]\n",
      "Launch site\n",
      "Payload[c]\n",
      "Orbit\n",
      "Customer\n",
      "\n",
      "Table 13 headers:\n",
      "Date and time (UTC)\n",
      "Version,Booster[b]\n",
      "Launch site\n",
      "Payload[c]\n",
      "Orbit\n",
      "Customer\n",
      "\n",
      "Table 14 headers:\n",
      "Date and time (UTC)\n",
      "Version,Booster[b]\n",
      "Launch site\n",
      "Payload[c]\n",
      "Orbit\n",
      "Customer\n",
      "\n",
      "Table 15 headers:\n",
      "Date and time (UTC)\n",
      "Version,Booster[b]\n",
      "Launch site\n",
      "Payload[c]\n",
      "Orbit\n",
      "Customer\n",
      "\n",
      "Table 16 headers:\n",
      "vteSpaceX missions and payloads\n",
      "Launch vehicles\n",
      "Falcon 1 missions\n",
      "Falcon 9 missions\n",
      "Demonstrations\n",
      "ISS logistics\n",
      "Crewed\n",
      "Commercialsatellites\n",
      "Scientificsatellites\n",
      "Militarysatellites\n",
      "Starlink\n",
      "Rideshares\n",
      "Transporter\n",
      "Bandwagon\n",
      "Falcon Heavy missions\n",
      "Starship missions\n",
      "Demonstrations\n",
      "Crewed\n",
      "CommercialSatellites\n",
      "\n",
      "Table 17 headers:\n",
      "Demonstrations\n",
      "ISS logistics\n",
      "Crewed\n",
      "Commercialsatellites\n",
      "Scientificsatellites\n",
      "Militarysatellites\n",
      "Starlink\n",
      "Rideshares\n",
      "Transporter\n",
      "Bandwagon\n",
      "\n",
      "Table 18 headers:\n",
      "Transporter\n",
      "Bandwagon\n",
      "\n",
      "Table 19 headers:\n",
      "Demonstrations\n",
      "Crewed\n",
      "CommercialSatellites\n",
      "\n",
      "Table 20 headers:\n",
      "vteSpaceX\n",
      "Launch vehicles\n",
      "Current\n",
      "In development\n",
      "Retired\n",
      "Cancelled\n",
      "Spacecraft\n",
      "Cargo\n",
      "Crewed\n",
      "Test vehicles\n",
      "Current\n",
      "Retired\n",
      "Unflown\n",
      "Rocket engines\n",
      "Lists of missions\n",
      "Launch facilities\n",
      "Orbital\n",
      "Atmospheric\n",
      "Landing sites\n",
      "Other facilities\n",
      "Support\n",
      "Contracts\n",
      "R&D programs\n",
      "Key people\n",
      "Related\n",
      "\n",
      "Table 21 headers:\n",
      "Current\n",
      "In development\n",
      "Retired\n",
      "Cancelled\n",
      "\n",
      "Table 22 headers:\n",
      "Cargo\n",
      "Crewed\n",
      "\n",
      "Table 23 headers:\n",
      "Current\n",
      "Retired\n",
      "Unflown\n",
      "\n",
      "Table 24 headers:\n",
      "Orbital\n",
      "Atmospheric\n",
      "\n",
      "Table 25 headers:\n",
      "vteSpaceflight lists and timelines\n",
      "General\n",
      "Human spaceflight\n",
      "General\n",
      "Salyut\n",
      "Mir\n",
      "ISS\n",
      "Tiangong\n",
      "Shuttle\n",
      "People\n",
      "EVA\n",
      "Solar Systemexploration\n",
      "Earth-orbitingsatellites\n",
      "Vehicles\n",
      "Launchesby rocket type\n",
      "Launches by spaceport\n",
      "Agencies, companiesand facilities\n",
      "Other mission listsand timelines\n",
      "\n",
      "Table 26 headers:\n",
      "General\n",
      "Salyut\n",
      "Mir\n",
      "ISS\n",
      "Tiangong\n",
      "Shuttle\n",
      "People\n",
      "EVA\n"
     ]
    }
   ],
   "source": [
    "# Use the find_all function in the BeautifulSoup object, with element type `table`\n",
    "# Assign the result to a list called `html_tables`\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Define the URL of the Falcon9 Launch Wiki page\n",
    "url = 'https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922'\n",
    "\n",
    "# Perform an HTTP GET request to fetch the page\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Request was successful!\")\n",
    "    html_content = response.text  # Store the HTML content\n",
    "\n",
    "    # Create a BeautifulSoup object and specify the parser\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find all tables on the page\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    # Loop through each table and extract header names\n",
    "    for idx, table in enumerate(tables):\n",
    "        print(f\"\\nTable {idx + 1} headers:\")\n",
    "        \n",
    "        # Find all table headers within the table\n",
    "        headers = table.find_all('th')\n",
    "        \n",
    "        # Extract and print the text of each header\n",
    "        for header in headers:\n",
    "            print(header.text.strip())\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the third table is our target table contains the actual launch records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request was successful!\n",
      "\n",
      "Extracting headers from the third table:\n",
      "Flight No.\n",
      "Date andtime (UTC)\n",
      "Version,Booster [b]\n",
      "Launch site\n",
      "Payload[c]\n",
      "Payload mass\n",
      "Orbit\n",
      "Customer\n",
      "Launchoutcome\n",
      "Boosterlanding\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'html_tables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_68/758520583.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to retrieve the page. Status code: {response.status_code}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mfirst_launch_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml_tables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_launch_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'html_tables' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's print the third table and check its content\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Define the URL of the Falcon9 Launch Wiki page\n",
    "url = 'https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922'\n",
    "\n",
    "# Perform an HTTP GET request to fetch the page\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Request was successful!\")\n",
    "    html_content = response.text  # Store the HTML content\n",
    "\n",
    "    # Create a BeautifulSoup object and specify the parser\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find all tables on the page\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    # Check if there are enough tables on the page\n",
    "    if len(tables) >= 3:\n",
    "        # The third table is at index 2 (since indices start at 0)\n",
    "        target_table = tables[2]\n",
    "        print(\"\\nExtracting headers from the third table:\")\n",
    "\n",
    "        # Find all table headers within the target table\n",
    "        headers = target_table.find_all('th')\n",
    "\n",
    "        # Extract and print the text of each header\n",
    "        for header in headers:\n",
    "            print(header.text.strip())\n",
    "    else:\n",
    "        print(\"There are not enough tables on the page.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "first_launch_table = html_tables[2]\n",
    "print(first_launch_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should able to see the columns names embedded in the table header elements `<th>` as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "<tr>\n",
    "<th scope=\"col\">Flight No.\n",
    "</th>\n",
    "<th scope=\"col\">Date and<br/>time (<a href=\"/wiki/Coordinated_Universal_Time\" title=\"Coordinated Universal Time\">UTC</a>)\n",
    "</th>\n",
    "<th scope=\"col\"><a href=\"/wiki/List_of_Falcon_9_first-stage_boosters\" title=\"List of Falcon 9 first-stage boosters\">Version,<br/>Booster</a> <sup class=\"reference\" id=\"cite_ref-booster_11-0\"><a href=\"#cite_note-booster-11\">[b]</a></sup>\n",
    "</th>\n",
    "<th scope=\"col\">Launch site\n",
    "</th>\n",
    "<th scope=\"col\">Payload<sup class=\"reference\" id=\"cite_ref-Dragon_12-0\"><a href=\"#cite_note-Dragon-12\">[c]</a></sup>\n",
    "</th>\n",
    "<th scope=\"col\">Payload mass\n",
    "</th>\n",
    "<th scope=\"col\">Orbit\n",
    "</th>\n",
    "<th scope=\"col\">Customer\n",
    "</th>\n",
    "<th scope=\"col\">Launch<br/>outcome\n",
    "</th>\n",
    "<th scope=\"col\"><a href=\"/wiki/Falcon_9_first-stage_landing_tests\" title=\"Falcon 9 first-stage landing tests\">Booster<br/>landing</a>\n",
    "</th></tr>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we just need to iterate through the `<th>` elements and apply the provided `extract_column_from_header()` to extract column name one by one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request was successful!\n",
      "\n",
      "Extracting headers from the third table:\n",
      "Flight No.\n",
      "Date and time ( UTC )\n",
      "Version, Booster   [ b ]\n",
      "Launch site\n",
      "Payload [ c ]\n",
      "Payload mass\n",
      "Orbit\n",
      "Customer\n",
      "Launch outcome\n",
      "Booster landing\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "column_names = []\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Define the URL of the Falcon9 Launch Wiki page\n",
    "url = 'https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922'\n",
    "\n",
    "# Function to extract column name from a header element\n",
    "def extract_column_from_header(th_element):\n",
    "    return th_element.get_text(separator=\" \").strip()\n",
    "\n",
    "# Perform an HTTP GET request to fetch the page\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Request was successful!\")\n",
    "    html_content = response.text  # Store the HTML content\n",
    "\n",
    "    # Create a BeautifulSoup object and specify the parser\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find all tables on the page\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    # Check if there are enough tables on the page (at least 3)\n",
    "    if len(tables) >= 3:\n",
    "        # The third table is at index 2 (since indices start at 0)\n",
    "        target_table = tables[2]\n",
    "        print(\"\\nExtracting headers from the third table:\")\n",
    "\n",
    "        # Find all table headers within the target table\n",
    "        headers = target_table.find_all('th')\n",
    "\n",
    "        # Extract and print the column names\n",
    "        for header in headers:\n",
    "            column_name = extract_column_from_header(header)\n",
    "            print(column_name)\n",
    "    else:\n",
    "        print(\"There are not enough tables on the page.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the extracted column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3: Create a data frame by parsing the launch HTML tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an empty dictionary with keys from the extracted column names in the previous task. Later, this dictionary will be converted into a Pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request was successful!\n",
      "\n",
      "Extracting headers from the third table:\n",
      "Empty DataFrame\n",
      "Columns: [Flight No., Date and time ( UTC ), Version, Booster   [ b ], Launch site, Payload [ c ], Payload mass, Orbit, Customer, Launch outcome, Booster landing, 1, 2, 3, 4, 5, 6, 7]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "launch_dict= dict.fromkeys(column_names)\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Define the URL of the Falcon9 Launch Wiki page\n",
    "url = 'https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922'\n",
    "\n",
    "# Function to extract column name from a header element\n",
    "def extract_column_from_header(th_element):\n",
    "    return th_element.get_text(separator=\" \").strip()\n",
    "\n",
    "# Perform an HTTP GET request to fetch the page\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Request was successful!\")\n",
    "    html_content = response.text  # Store the HTML content\n",
    "\n",
    "    # Create a BeautifulSoup object and specify the parser\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find all tables on the page\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    # Check if there are enough tables on the page (at least 3)\n",
    "    if len(tables) >= 3:\n",
    "        # The third table is at index 2 (since indices start at 0)\n",
    "        target_table = tables[2]\n",
    "        print(\"\\nExtracting headers from the third table:\")\n",
    "\n",
    "        # Extract column names\n",
    "        headers = target_table.find_all('th')\n",
    "        column_names = [extract_column_from_header(header) for header in headers]\n",
    "\n",
    "        # Create an empty dictionary to hold the data\n",
    "        launch_data = {col: [] for col in column_names}\n",
    "\n",
    "        # Extract the table rows\n",
    "        rows = target_table.find_all('tr')[1:]  # Skip the header row\n",
    "\n",
    "        for row in rows:\n",
    "            # Extract each cell (td) from the row\n",
    "            cells = row.find_all('td')\n",
    "\n",
    "            # Check if the row has the correct number of cells (to match columns)\n",
    "            if len(cells) == len(column_names):\n",
    "                for idx, cell in enumerate(cells):\n",
    "                    # Append the cell data to the corresponding column in the dictionary\n",
    "                    launch_data[column_names[idx]].append(cell.get_text(separator=\" \").strip())\n",
    "\n",
    "        # Convert the dictionary into a Pandas DataFrame\n",
    "        df = pd.DataFrame(launch_data)\n",
    "\n",
    "        # Display the DataFrame\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"There are not enough tables on the page.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we just need to fill up the `launch_dict` with launch records extracted from table rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, HTML tables in Wiki pages are likely to contain unexpected annotations and other types of noises, such as reference links `B0004.1[8]`, missing values `N/A [e]`, inconsistent formatting, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the parsing process, we have provided an incomplete code snippet below to help you to fill up the `launch_dict`. Please complete the following code snippet with TODOs or you can choose to write your own logic to parse all launch tables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request was successful!\n",
      "\n",
      "Extracting headers from the third table:\n",
      "Row length mismatch. Expected 17 but got 9. Filling with N/A.\n",
      "Row length mismatch. Expected 17 but got 1. Filling with N/A.\n",
      "Row length mismatch. Expected 17 but got 9. Filling with N/A.\n",
      "Row length mismatch. Expected 17 but got 1. Filling with N/A.\n",
      "Row length mismatch. Expected 17 but got 9. Filling with N/A.\n",
      "Row length mismatch. Expected 17 but got 1. Filling with N/A.\n",
      "Row length mismatch. Expected 17 but got 9. Filling with N/A.\n",
      "Row length mismatch. Expected 17 but got 5. Filling with N/A.\n",
      "Row length mismatch. Expected 17 but got 1. Filling with N/A.\n",
      "Row length mismatch. Expected 17 but got 9. Filling with N/A.\n",
      "Row length mismatch. Expected 17 but got 1. Filling with N/A.\n",
      "Row length mismatch. Expected 17 but got 9. Filling with N/A.\n",
      "Row length mismatch. Expected 17 but got 1. Filling with N/A.\n",
      "Row length mismatch. Expected 17 but got 9. Filling with N/A.\n",
      "Row length mismatch. Expected 17 but got 1. Filling with N/A.\n",
      "                                          Flight No.  \\\n",
      "0                                 4 June 2010, 18:45   \n",
      "1  First flight of Falcon 9 v1.0. [ 11 ]  Used a ...   \n",
      "2                      8 December 2010, 15:43 [ 13 ]   \n",
      "3  Maiden flight of  Dragon capsule , consisting ...   \n",
      "4                          22 May 2012, 07:44 [ 17 ]   \n",
      "\n",
      "         Date and time ( UTC ) Version, Booster   [ b ]  \\\n",
      "0  F9 v1.0 [ 7 ] B0003.1 [ 8 ]           CCAFS , SLC-40   \n",
      "1                          N/A                      N/A   \n",
      "2  F9 v1.0 [ 7 ] B0004.1 [ 8 ]           CCAFS , SLC-40   \n",
      "3                          N/A                      N/A   \n",
      "4  F9 v1.0 [ 7 ] B0005.1 [ 8 ]           CCAFS , SLC-40   \n",
      "\n",
      "                                     Launch site             Payload [ c ]  \\\n",
      "0           Dragon Spacecraft Qualification Unit                             \n",
      "1                                            N/A                       N/A   \n",
      "2          Dragon   demo flight C1 (Dragon C101)                             \n",
      "3                                            N/A                       N/A   \n",
      "4  Dragon   demo flight C2+ [ 18 ] (Dragon C102)  525 kg (1,157 lb) [ 19 ]   \n",
      "\n",
      "   Payload mass                  Orbit        Customer  \\\n",
      "0           LEO                 SpaceX         Success   \n",
      "1           N/A                    N/A             N/A   \n",
      "2  LEO  ( ISS )  NASA  ( COTS ) \\n NRO   Success [ 9 ]   \n",
      "3           N/A                    N/A             N/A   \n",
      "4  LEO  ( ISS )         NASA  ( COTS )  Success [ 20 ]   \n",
      "\n",
      "                     Launch outcome Booster landing    1    2    3    4    5  \\\n",
      "0  Failure [ 9 ] [ 10 ] (parachute)             N/A  N/A  N/A  N/A  N/A  N/A   \n",
      "1                               N/A             N/A  N/A  N/A  N/A  N/A  N/A   \n",
      "2  Failure [ 9 ] [ 14 ] (parachute)             N/A  N/A  N/A  N/A  N/A  N/A   \n",
      "3                               N/A             N/A  N/A  N/A  N/A  N/A  N/A   \n",
      "4                        No attempt             N/A  N/A  N/A  N/A  N/A  N/A   \n",
      "\n",
      "     6    7  \n",
      "0  N/A  N/A  \n",
      "1  N/A  N/A  \n",
      "2  N/A  N/A  \n",
      "3  N/A  N/A  \n",
      "4  N/A  N/A  \n"
     ]
    }
   ],
   "source": [
    "extracted_row = 0\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Define the URL of the Falcon9 Launch Wiki page\n",
    "url = 'https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922'\n",
    "\n",
    "# Function to extract column name from a header element\n",
    "def extract_column_from_header(th_element):\n",
    "    return th_element.get_text(separator=\" \").strip()\n",
    "\n",
    "# Function to clean cell content by removing unwanted reference links and extra spaces\n",
    "def clean_cell_data(cell):\n",
    "    # Remove reference links and unnecessary characters\n",
    "    cleaned_data = cell.get_text(separator=\" \").strip()\n",
    "    return cleaned_data.replace(\"\\xa0\", \" \").replace(\"[edit]\", \"\")  # Clean up non-breaking spaces and other annotations\n",
    "\n",
    "# Perform an HTTP GET request to fetch the page\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Request was successful!\")\n",
    "    html_content = response.text  # Store the HTML content\n",
    "\n",
    "    # Create a BeautifulSoup object and specify the parser\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find all tables on the page\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    # Check if there are enough tables on the page (at least 3)\n",
    "    if len(tables) >= 3:\n",
    "        # The third table is at index 2 (since indices start at 0)\n",
    "        target_table = tables[2]\n",
    "        print(\"\\nExtracting headers from the third table:\")\n",
    "\n",
    "        # Extract column names\n",
    "        headers = target_table.find_all('th')\n",
    "        column_names = [extract_column_from_header(header) for header in headers]\n",
    "\n",
    "        # Create an empty dictionary to hold the data\n",
    "        launch_dict = {col: [] for col in column_names}\n",
    "\n",
    "        # Extract the table rows\n",
    "        rows = target_table.find_all('tr')[1:]  # Skip the header row\n",
    "\n",
    "        for row in rows:\n",
    "            # Extract each cell (td) from the row\n",
    "            cells = row.find_all('td')\n",
    "\n",
    "            # Check if the row has the correct number of cells (to match columns)\n",
    "            if len(cells) == len(column_names):\n",
    "                for idx, cell in enumerate(cells):\n",
    "                    # Clean and append the cell data to the corresponding column in the dictionary\n",
    "                    launch_dict[column_names[idx]].append(clean_cell_data(cell))\n",
    "            else:\n",
    "                # Handle cases with inconsistent number of cells (e.g., missing data or annotations)\n",
    "                print(f\"Row length mismatch. Expected {len(column_names)} but got {len(cells)}. Filling with N/A.\")\n",
    "                for idx in range(len(column_names)):\n",
    "                    if idx < len(cells):\n",
    "                        launch_dict[column_names[idx]].append(clean_cell_data(cells[idx]))\n",
    "                    else:\n",
    "                        launch_dict[column_names[idx]].append(\"N/A\")  # Fill missing columns with N/A\n",
    "\n",
    "        # Convert the dictionary into a Pandas DataFrame\n",
    "        df = pd.DataFrame(launch_dict)\n",
    "\n",
    "        # Display the DataFrame\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"There are not enough tables on the page.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have fill in the parsed launch record values into `launch_dict`, you can create a dataframe from it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df= pd.DataFrame({ key:pd.Series(value) for key, value in launch_dict.items() })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now export it to a <b>CSV</b> for the next section, but to make the answers consistent and in case you have difficulties finishing this lab. \n",
    "\n",
    "Following labs will be using a provided dataset to make each lab independent. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>df.to_csv('spacex_web_scraped.csv', index=False)</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.linkedin.com/in/yan-luo-96288783/\">Yan Luo</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.linkedin.com/in/nayefaboutayoun/\">Nayef Abou Tayoun</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description      |\n",
    "| ----------------- | ------- | ---------- | ----------------------- |\n",
    "| 2021-06-09        | 1.0     | Yan Luo    | Tasks updates           |\n",
    "| 2020-11-10        | 1.0     | Nayef      | Created the initial version |\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Â© 2021 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "prev_pub_hash": "64f1b0aac408997185c47caba18730e0028b75e7934a0e5bf0ae73c5cb7ba677"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
